{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-THsA8blXAH1Hh52_ZjChc59UnGPGj6x",
      "authorship_tag": "ABX9TyOkXndKBUp1qYKh/7xkN9Q4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mheronanh/MBKM-Xirka-HRM/blob/main/main/Software/CNN-based/Training%20VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ97hevgxoQH",
        "outputId": "a85b564e-d327-4611-87d7-c32ce29ecb3a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUYa-s3axrKz"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os.path\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58323ctPyEny"
      },
      "source": [
        "image_dir = Path('/content/drive/MyDrive/Data/CNN PCA/source2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOhd24AkyPNk"
      },
      "source": [
        "filepaths = pd.Series(list(image_dir.glob(r'**/*.png')), name='Filepath').astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzOkBEz_yQVP"
      },
      "source": [
        "bpms = pd.Series(filepaths.apply(lambda x: (os.path.split(os.path.split(x)[1])[1])[:-4]), name='BPMS').astype(np.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kv6Sr0CyfTA"
      },
      "source": [
        "images = pd.concat([filepaths, bpms], axis=1).sample(frac=1.0, random_state=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdsAJeS4yzl8"
      },
      "source": [
        "image_df = images.sample(len(images), random_state = 1).reset_index(drop=True)\n",
        "train_df, test_df = train_test_split(image_df, train_size= 0.7, shuffle= True, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnJWevKetjLk",
        "outputId": "d3be402a-03be-4ddc-d768-67306a1b650d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "739"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtumSRayy4LV",
        "outputId": "49ad2245-d6a1-491e-bb71-884d8d673c4b"
      },
      "source": [
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    validation_split=0.4\n",
        ")\n",
        "\n",
        "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        ")\n",
        "\n",
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='BPMS',\n",
        "    target_size=(216, 144),\n",
        "    color_mode='rgb',\n",
        "    class_mode='raw',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='BPMS',\n",
        "    target_size=(216, 144),\n",
        "    color_mode='rgb',\n",
        "    class_mode='raw',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='BPMS',\n",
        "    target_size=(216, 144),\n",
        "    color_mode='rgb',\n",
        "    class_mode='raw',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 311 validated image filenames.\n",
            "Found 206 validated image filenames.\n",
            "Found 222 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.VGG16(\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(216, 144, 3),\n",
        "    include_top=False)  # Do not include the ImageNet classifier at the top."
      ],
      "metadata": {
        "id": "KWHofnBhGPS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3e1170c-1385-4586-d20e-779ebb4fd945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "vky9ioHFG4DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlW4WURoy_Yv"
      },
      "source": [
        "inputs = keras.Input(shape=(216, 144, 3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base_model(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(1, activation='linear')(x)\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByDn22sDzEaJ",
        "outputId": "391b3e97-2702-4852-e620-b86a78af327a"
      },
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mae'\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    validation_data=val_images,\n",
        "    epochs=50,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=5,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - 302s 30s/step - loss: 87.9104 - val_loss: 82.9524\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 161s 17s/step - loss: 79.8305 - val_loss: 74.9459\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 179s 19s/step - loss: 71.9295 - val_loss: 66.9417\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 161s 17s/step - loss: 63.8760 - val_loss: 58.9446\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 163s 17s/step - loss: 55.8203 - val_loss: 50.9428\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 47.8946 - val_loss: 42.9427\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 39.9071 - val_loss: 34.9372\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 164s 17s/step - loss: 32.0676 - val_loss: 26.9610\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 163s 17s/step - loss: 24.4663 - val_loss: 19.9815\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 164s 17s/step - loss: 18.1547 - val_loss: 15.2538\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 163s 17s/step - loss: 14.1962 - val_loss: 12.6233\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 12.3235 - val_loss: 12.1525\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 12.0606 - val_loss: 12.1202\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 12.0348 - val_loss: 12.1113\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 12.0052 - val_loss: 12.0660\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 11.9416 - val_loss: 12.0102\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 11.8990 - val_loss: 11.9428\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 163s 17s/step - loss: 11.8385 - val_loss: 11.8849\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 11.7831 - val_loss: 11.8321\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 11.7320 - val_loss: 11.7886\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 161s 17s/step - loss: 11.6803 - val_loss: 11.7400\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 161s 17s/step - loss: 11.6332 - val_loss: 11.6984\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 161s 17s/step - loss: 11.5921 - val_loss: 11.6548\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 161s 17s/step - loss: 11.5396 - val_loss: 11.6157\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 11.5031 - val_loss: 11.5750\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 161s 17s/step - loss: 11.4531 - val_loss: 11.5487\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 11.4136 - val_loss: 11.5134\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 11.3675 - val_loss: 11.4673\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 11.3272 - val_loss: 11.4316\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 161s 17s/step - loss: 11.2819 - val_loss: 11.3885\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 11.2342 - val_loss: 11.3518\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 11.1941 - val_loss: 11.3154\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 11.1501 - val_loss: 11.2868\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 161s 17s/step - loss: 11.1209 - val_loss: 11.2400\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 11.0726 - val_loss: 11.2128\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 161s 17s/step - loss: 11.0398 - val_loss: 11.1861\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 11.0047 - val_loss: 11.1458\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.9708 - val_loss: 11.1069\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.9309 - val_loss: 11.0756\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.9066 - val_loss: 11.0502\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.8821 - val_loss: 11.0236\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.8436 - val_loss: 11.0040\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.8195 - val_loss: 10.9673\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 161s 17s/step - loss: 10.7926 - val_loss: 10.9469\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.7689 - val_loss: 10.9466\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.7388 - val_loss: 10.9110\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 163s 17s/step - loss: 10.7131 - val_loss: 10.8799\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.6915 - val_loss: 10.8721\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.6757 - val_loss: 10.8625\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.6550 - val_loss: 10.8196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtauhiOCbVuy",
        "outputId": "e0bb7969-015f-46fa-a65e-06d300bf4145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training #2**"
      ],
      "metadata": {
        "id": "9oH6GJm8bXf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snKT2DrJbdl6",
        "outputId": "b2c453a7-10d9-42c3-f15a-249a6ca1c852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "loaded_model.compile(\n",
        "    optimizer=opt,\n",
        "    loss='mae'\n",
        ")\n",
        "\n",
        "history = loaded_model.fit(\n",
        "    train_images,\n",
        "    validation_data=val_images,\n",
        "    epochs=20,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=5,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "6x6OeF09bhBK",
        "outputId": "1ccf223d-fc48-4f4e-bf87-cf09c51f0a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - 163s 17s/step - loss: 10.6329 - val_loss: 10.8153\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.6253 - val_loss: 10.8138\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.6194 - val_loss: 10.8136\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.6171 - val_loss: 10.8098\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.6115 - val_loss: 10.8078\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 162s 17s/step - loss: 10.6077 - val_loss: 10.8062\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 10.6040"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-eab5fc4f80ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         )\n\u001b[1;32m     17\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1261\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1264\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1538\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    947\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-9e-uSGzHRx",
        "outputId": "2a92cf7d-1087-4223-ef61-45309d54f61f"
      },
      "source": [
        "predicted_bpm = np.squeeze(model.predict(test_images))\n",
        "true_bpm  = test_images.labels\n",
        "\n",
        "rmse = np.sqrt(model.evaluate(test_images, verbose=0))\n",
        "print('Test RMSE: {:.5f}'.format(rmse))\n",
        "\n",
        "r2 = r2_score(true_bpm, predicted_bpm)\n",
        "print('Test R2 Score: {:.5f}'.format(r2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE: 3.12256\n",
            "Test R2 Score: -0.06064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJanAxbb1khV",
        "outputId": "6b353593-c4de-47a9-e005-99bd6851259c"
      },
      "source": [
        "max(predicted_bpm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88.94751"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "metadata": {
        "id": "mSq2UC2flGdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a22fb774-9162-436f-afd0-b58ddc8ba091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "loaded_model.compile(\n",
        "    optimizer=opt,\n",
        "    loss='mae'\n",
        ")\n",
        "\n",
        "history = loaded_model.fit(\n",
        "    train_images,\n",
        "    validation_data=val_images,\n",
        "    epochs=20,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=5,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsHmYtcK54Y7",
        "outputId": "bc5d8945-45f8-422c-e416-5bbc3102b1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "22/22 [==============================] - 355s 16s/step - loss: 9.1366 - val_loss: 10.8253\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 359s 17s/step - loss: 9.1184 - val_loss: 10.8258\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 360s 17s/step - loss: 9.1125 - val_loss: 10.8247\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 356s 16s/step - loss: 9.1128 - val_loss: 10.8241\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 356s 16s/step - loss: 9.1120 - val_loss: 10.8217\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 356s 16s/step - loss: 9.1085 - val_loss: 10.8212\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 356s 16s/step - loss: 9.1077 - val_loss: 10.8213\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 355s 16s/step - loss: 9.1039 - val_loss: 10.8205\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 355s 16s/step - loss: 9.1037 - val_loss: 10.8191\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 355s 17s/step - loss: 9.1019 - val_loss: 10.8185\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 355s 16s/step - loss: 9.1005 - val_loss: 10.8179\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 355s 16s/step - loss: 9.1015 - val_loss: 10.8176\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 355s 16s/step - loss: 9.0976 - val_loss: 10.8160\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 354s 16s/step - loss: 9.0945 - val_loss: 10.8147\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 354s 16s/step - loss: 9.0922 - val_loss: 10.8144\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 354s 16s/step - loss: 9.0927 - val_loss: 10.8143\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 355s 16s/step - loss: 9.0922 - val_loss: 10.8128\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 357s 17s/step - loss: 9.0882 - val_loss: 10.8121\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 357s 16s/step - loss: 9.0856 - val_loss: 10.8132\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 357s 17s/step - loss: 9.0870 - val_loss: 10.8129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_bpm = np.squeeze(loaded_model.predict(test_images))\n",
        "true_bpm  = test_images.labels\n",
        "\n",
        "rmse = np.sqrt(loaded_model.evaluate(test_images, verbose=0))\n",
        "print('Test RMSE: {:.5f}'.format(rmse))\n",
        "\n",
        "r2 = r2_score(true_bpm, predicted_bpm)\n",
        "print('Test R2 Score: {:.5f}'.format(r2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYh_St5E6YPM",
        "outputId": "2cfaa801-138f-4ec3-baf5-f1e82d97e4bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE: 3.12005\n",
            "Test R2 Score: -0.04595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(np.abs(predicted_bpm-true_bpm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuncshdPYgWx",
        "outputId": "7e636e39-37f9-47f4-d22c-aa8fecf8a2bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.734738310185408"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# serialize model to JSON\n",
        "model_json = loaded_model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "loaded_model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRawQuMaZ2n-",
        "outputId": "e36ecc50-bbab-4648-b6dc-c786328b02b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(model_json)\n",
        "# load weights into new model\n",
        "model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXl3JH_QaLEa",
        "outputId": "c2287bd8-4c2b-45b1-8265-ef333dbbe27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.00001)\n",
        "loaded_model.compile(\n",
        "    optimizer=opt,\n",
        "    loss='mae'\n",
        ")\n",
        "\n",
        "history = loaded_model.fit(\n",
        "    train_images,\n",
        "    validation_data=val_images,\n",
        "    epochs=10,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=5,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tgfyp4KUbAk9",
        "outputId": "efd3107c-4892-4626-feb4-009d6d7dc58e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 356s 16s/step - loss: 9.0843 - val_loss: 10.8126\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 356s 16s/step - loss: 9.0836 - val_loss: 10.8126\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 356s 16s/step - loss: 9.0836 - val_loss: 10.8126\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 356s 16s/step - loss: 9.0829 - val_loss: 10.8124\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 356s 17s/step - loss: 9.0831 - val_loss: 10.8123\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 357s 17s/step - loss: 9.0826 - val_loss: 10.8121\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 357s 17s/step - loss: 9.0825 - val_loss: 10.8120\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 357s 17s/step - loss: 9.0829 - val_loss: 10.8120\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 357s 17s/step - loss: 9.0824 - val_loss: 10.8119\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 356s 16s/step - loss: 9.0822 - val_loss: 10.8118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(model_json)\n",
        "# load weights into new model\n",
        "model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "metadata": {
        "id": "uAK4Db1ObFMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba0a19f-2bd1-486d-e78b-17c2803f6395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,10):  \n",
        "  test_image_dir = Path('/content/drive/MyDrive/Data/CNN ICA/source2/v{}'.format(i))\n",
        "  test_filepaths = pd.Series(list(test_image_dir.glob(r'**/*.png')), name='Filepath').astype(str)\n",
        "  test_bpms = pd.Series(test_filepaths.apply(lambda x: (os.path.split(os.path.split(x)[1])[1])[:-4]), name='BPMS').astype(np.float64)\n",
        "  test_images = pd.concat([test_filepaths, test_bpms], axis=1).sample(frac=1.0, random_state=1).reset_index(drop=True)\n",
        "  test_image_df = test_images.sample(len(test_images), random_state = 1).reset_index(drop=True)\n",
        "  test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "  )\n",
        "  test_images_flow = test_generator.flow_from_dataframe(\n",
        "      dataframe=test_image_df,\n",
        "      x_col='Filepath',\n",
        "      y_col='BPMS',\n",
        "      target_size=(216, 144),\n",
        "      color_mode='rgb',\n",
        "      class_mode='raw',\n",
        "      batch_size=32,\n",
        "      shuffle=False\n",
        "  )\n",
        "  predicted_bpm = np.squeeze(model.predict(test_images_flow))\n",
        "  true_bpm  = test_images_flow.labels\n",
        "  print(\"v\" + str(i) + \": \" + str(np.mean(np.abs(predicted_bpm-true_bpm))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTDGEMp3I4a2",
        "outputId": "d2760803-438b-4da3-a4ac-2767744069fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 107 validated image filenames.\n",
            "v1: 8.21073215110922\n",
            "Found 49 validated image filenames.\n",
            "v2: 8.672826237697386\n",
            "Found 103 validated image filenames.\n",
            "v3: 8.431057295547973\n",
            "Found 106 validated image filenames.\n",
            "v4: 7.422072099514161\n",
            "Found 107 validated image filenames.\n",
            "v5: 7.070457216765391\n",
            "Found 106 validated image filenames.\n",
            "v6: 7.952692159044876\n",
            "Found 105 validated image filenames.\n",
            "v7: 21.639760209077576\n",
            "Found 96 validated image filenames.\n",
            "v8: 7.224693856064445\n",
            "Found 104 validated image filenames.\n",
            "v9: 8.509395839531134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,3):  \n",
        "  test_image_dir = Path('/content/drive/MyDrive/Data/CNN ICA/source3/v{}'.format(i))\n",
        "  test_filepaths = pd.Series(list(test_image_dir.glob(r'**/*.png')), name='Filepath').astype(str)\n",
        "  test_bpms = pd.Series(test_filepaths.apply(lambda x: (os.path.split(os.path.split(x)[1])[1])[:-4]), name='BPMS').astype(np.float64)\n",
        "  test_images = pd.concat([test_filepaths, test_bpms], axis=1).sample(frac=1.0, random_state=1).reset_index(drop=True)\n",
        "  test_image_df = test_images.sample(len(test_images), random_state = 1).reset_index(drop=True)\n",
        "  test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "  )\n",
        "  test_images_flow = test_generator.flow_from_dataframe(\n",
        "      dataframe=test_image_df,\n",
        "      x_col='Filepath',\n",
        "      y_col='BPMS',\n",
        "      target_size=(216, 144),\n",
        "      color_mode='rgb',\n",
        "      class_mode='raw',\n",
        "      batch_size=32,\n",
        "      shuffle=False\n",
        "  )\n",
        "  predicted_bpm = np.squeeze(model.predict(test_images_flow))\n",
        "  true_bpm  = test_images_flow.labels\n",
        "  print(\"v\" + str(i) + \": \" + str(np.mean(np.abs(predicted_bpm-true_bpm))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6i961kMJm7k",
        "outputId": "71923668-da63-49ed-eb50-c34a2c153995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 104 validated image filenames.\n",
            "v1: 8.24624493970874\n",
            "Found 106 validated image filenames.\n",
            "v2: 7.982627853901193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(4,5):  \n",
        "  test_image_dir = Path('/content/drive/MyDrive/Data/CNN ICA/source3/v{}'.format(i))\n",
        "  test_filepaths = pd.Series(list(test_image_dir.glob(r'**/*.png')), name='Filepath').astype(str)\n",
        "  test_bpms = pd.Series(test_filepaths.apply(lambda x: (os.path.split(os.path.split(x)[1])[1])[:-4]), name='BPMS').astype(np.float64)\n",
        "  test_images = pd.concat([test_filepaths, test_bpms], axis=1).sample(frac=1.0, random_state=1).reset_index(drop=True)\n",
        "  test_image_df = test_images.sample(len(test_images), random_state = 1).reset_index(drop=True)\n",
        "  test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "  )\n",
        "  test_images_flow = test_generator.flow_from_dataframe(\n",
        "      dataframe=test_image_df,\n",
        "      x_col='Filepath',\n",
        "      y_col='BPMS',\n",
        "      target_size=(216, 144),\n",
        "      color_mode='rgb',\n",
        "      class_mode='raw',\n",
        "      batch_size=32,\n",
        "      shuffle=False\n",
        "  )\n",
        "  predicted_bpm = np.squeeze(model.predict(test_images_flow))\n",
        "  true_bpm  = test_images_flow.labels\n",
        "  print(\"v\" + str(i) + \": \" + str(np.mean(np.abs(predicted_bpm-true_bpm))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-woRWH-K5Oh",
        "outputId": "84554a43-a7bf-431b-94dc-5dbf416ba0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 105 validated image filenames.\n",
            "v4: 7.943319598503688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_dir = Path('/content/drive/MyDrive/Data/CNN ICA/source3/v3-v5')\n",
        "test_filepaths = pd.Series(list(test_image_dir.glob(r'**/*.png')), name='Filepath').astype(str)\n",
        "test_bpms = pd.Series(test_filepaths.apply(lambda x: (os.path.split(os.path.split(x)[1])[1])[:-4]), name='BPMS').astype(np.float64)\n",
        "test_images = pd.concat([test_filepaths, test_bpms], axis=1).sample(frac=1.0, random_state=1).reset_index(drop=True)\n",
        "test_image_df = test_images.sample(len(test_images), random_state = 1).reset_index(drop=True)\n",
        "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "  )\n",
        "test_images_flow = test_generator.flow_from_dataframe(\n",
        "      dataframe=test_image_df,\n",
        "      x_col='Filepath',\n",
        "      y_col='BPMS',\n",
        "      target_size=(216, 144),\n",
        "      color_mode='rgb',\n",
        "      class_mode='raw',\n",
        "      batch_size=32,\n",
        "      shuffle=False\n",
        "  )\n",
        "predicted_bpm = np.squeeze(model.predict(test_images_flow))\n",
        "true_bpm  = test_images_flow.labels\n",
        "print(\"v\" + str(i) + \": \" + str(np.mean(np.abs(predicted_bpm-true_bpm))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h5xOhfyLf3D",
        "outputId": "c29c1e75-5eaf-4124-8b4b-ccff912873bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 210 validated image filenames.\n",
            "v4: 8.533449242115305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_FZGpLb3L4zp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}